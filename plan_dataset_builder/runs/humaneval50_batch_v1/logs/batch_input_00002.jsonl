{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/106:b2:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/106\n- batch_number: 2\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Failure-Modes-First\", \"Minimal-Solution-First\", \"Spec-First\", \"Examples-First\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/106\n\n[PRIMARY_TASK]\n\ndef f(n):\n    \"\"\" Implement the function f that takes n as a parameter,\n    and returns a list of size n, such that the value of the element at index i is the factorial of i if i is even\n    or the sum of numbers from 1 to i otherwise.\n    i starts from 1.\n    the factorial of i is the multiplication of the numbers from 1 to i (1 * 2 * ... * i).\n    Example:\n    f(5) == [1, 2, 6, 24, 15]\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nf\n\ntask_id:\nHumanEval/106\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/113:b1:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/113\n- batch_number: 1\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Edge-Cases-First\", \"Invariants-First\", \"Pseudocode-First\", \"Decompose-Then-Solve\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/113\n\n[PRIMARY_TASK]\n\ndef odd_count(lst):\n    \"\"\"Given a list of strings, where each string consists of only digits, return a list.\n    Each element i of the output should be \"the number of odd elements in the\n    string i of the input.\" where all the i's should be replaced by the number\n    of odd digits in the i'th string of the input.\n\n    >>> odd_count(['1234567'])\n    [\"the number of odd elements 4n the str4ng 4 of the 4nput.\"]\n    >>> odd_count(['3',\"11111111\"])\n    [\"the number of odd elements 1n the str1ng 1 of the 1nput.\",\n     \"the number of odd elements 8n the str8ng 8 of the 8nput.\"]\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nodd_count\n\ntask_id:\nHumanEval/113\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/116:b1:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/116\n- batch_number: 1\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Test-Design-Mental\", \"Failure-Modes-First\", \"Minimal-Solution-First\", \"Spec-First\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/116\n\n[PRIMARY_TASK]\n\ndef sort_array(arr):\n    \"\"\"\n    In this Kata, you have to sort an array of non-negative integers according to\n    number of ones in their binary representation in ascending order.\n    For similar number of ones, sort based on decimal value.\n\n    It must be implemented like this:\n    >>> sort_array([1, 5, 2, 3, 4]) == [1, 2, 3, 4, 5]\n    >>> sort_array([-2, -3, -4, -5, -6]) == [-6, -5, -4, -3, -2]\n    >>> sort_array([1, 0, 2, 3, 4]) [0, 1, 2, 3, 4]\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nsort_array\n\ntask_id:\nHumanEval/116\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/116:b3:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/116\n- batch_number: 3\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Decompose-Then-Solve\", \"Brute-Force-Then-Optimize\", \"Type-Driven\", \"Complexity-Guardrails\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/116\n\n[PRIMARY_TASK]\n\ndef sort_array(arr):\n    \"\"\"\n    In this Kata, you have to sort an array of non-negative integers according to\n    number of ones in their binary representation in ascending order.\n    For similar number of ones, sort based on decimal value.\n\n    It must be implemented like this:\n    >>> sort_array([1, 5, 2, 3, 4]) == [1, 2, 3, 4, 5]\n    >>> sort_array([-2, -3, -4, -5, -6]) == [-6, -5, -4, -3, -2]\n    >>> sort_array([1, 0, 2, 3, 4]) [0, 1, 2, 3, 4]\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nsort_array\n\ntask_id:\nHumanEval/116\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/124:b2:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/124\n- batch_number: 2\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Complexity-Guardrails\", \"Test-Design-Mental\", \"Failure-Modes-First\", \"Minimal-Solution-First\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/124\n\n[PRIMARY_TASK]\n\ndef valid_date(date):\n    \"\"\"You have to write a function which validates a given date string and\n    returns True if the date is valid otherwise False.\n    The date is valid if all of the following rules are satisfied:\n    1. The date string is not empty.\n    2. The number of days is not less than 1 or higher than 31 days for months 1,3,5,7,8,10,12. And the number of days is not less than 1 or higher than 30 days for months 4,6,9,11. And, the number of days is not less than 1 or higher than 29 for the month 2.\n    3. The months should not be less than 1 or higher than 12.\n    4. The date should be in the format: mm-dd-yyyy\n\n    for example: \n    valid_date('03-11-2000') => True\n\n    valid_date('15-01-2012') => False\n\n    valid_date('04-0-2040') => False\n\n    valid_date('06-04-2020') => True\n\n    valid_date('06/04/2020') => False\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nvalid_date\n\ntask_id:\nHumanEval/124\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/133:b1:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/133\n- batch_number: 1\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Spec-First\", \"Examples-First\", \"Edge-Cases-First\", \"Invariants-First\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/133\n\n[PRIMARY_TASK]\n\n\ndef sum_squares(lst):\n    \"\"\"You are given a list of numbers.\n    You need to return the sum of squared numbers in the given list,\n    round each element in the list to the upper int(Ceiling) first.\n    Examples:\n    For lst = [1,2,3] the output should be 14\n    For lst = [1,4,9] the output should be 98\n    For lst = [1,3,5,7] the output should be 84\n    For lst = [1.4,4.2,0] the output should be 29\n    For lst = [-2.4,1,1] the output should be 6\n    \n\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nsum_squares\n\ntask_id:\nHumanEval/133\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
{"custom_id": "humaneval50_batch_v1:humaneval:HumanEval/14:b2:a1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-4.1-mini", "input": "You are generating planning-only artifacts for benchmark task analysis.\n\nReturn ONLY valid JSON (no markdown, no prose), as a JSON array of exactly 4 plan objects.\n\nTask metadata:\n- dataset: humaneval\n- task_id: HumanEval/14\n- batch_number: 2\n- schema_version: 1.0\n\nAllowed strategy labels for this call (use exactly one per plan, and each of the 4 plans must use a different label from this set):\n[\"Spec-First\", \"Examples-First\", \"Edge-Cases-First\", \"Invariants-First\"]\n\nStructural bounds:\n{\"max_depth\": 2, \"max_total_steps\": 25, \"min_steps\": 4}\n\nHard requirements:\n1) Output a JSON array of length 4.\n2) Each plan object must contain:\n   - schema_version (must equal \"1.0\")\n   - strategy_label (must be one of the allowed labels above)\n   - unique_step (non-empty, and different across the 4 plans)\n   - steps (list with at least 4 top-level step objects)\n3) Each step object must contain:\n   - id (e.g. \"1\", \"2\", \"2.1\")\n   - action (imperative, non-empty)\n   - rationale (non-empty)\n   - optional checks: list[string]\n   - optional substeps: list[step]\n4) Avoid placeholders like TBD/TODO/fill in/unknown.\n5) Respect the max depth and max total step bounds.\n\nTask:\n[DATASET] humaneval\n[TASK_ID] HumanEval/14\n\n[PRIMARY_TASK]\nfrom typing import List\n\n\ndef all_prefixes(string: str) -> List[str]:\n    \"\"\" Return list of all prefixes from shortest to longest of the input string\n    >>> all_prefixes('abc')\n    ['a', 'ab', 'abc']\n    \"\"\"\n\n\n[CONTEXT_FIELDS]\nentry_point:\nall_prefixes\n\ntask_id:\nHumanEval/14\n\n", "temperature": 0.2, "top_p": 1.0, "max_output_tokens": 2500, "seed": 42, "text": {"format": {"type": "json_schema", "name": "plan_group", "schema": {"type": "object", "additionalProperties": false, "required": ["plans"], "properties": {"plans": {"type": "array", "minItems": 4, "maxItems": 4, "items": {"type": "object", "additionalProperties": false, "required": ["schema_version", "strategy_label", "unique_step", "steps"], "properties": {"schema_version": {"type": "string", "const": "1.0"}, "strategy_label": {"type": "string"}, "unique_step": {"type": "string", "minLength": 1}, "steps": {"type": "array", "items": {"$ref": "#/$defs/step"}, "minItems": 1}}}}}, "$defs": {"step": {"type": "object", "additionalProperties": false, "required": ["id", "action", "rationale", "checks", "substeps"], "properties": {"id": {"type": "string", "minLength": 1}, "action": {"type": "string", "minLength": 1}, "rationale": {"type": "string", "minLength": 1}, "checks": {"anyOf": [{"type": "array", "items": {"type": "string"}}, {"type": "null"}]}, "substeps": {"anyOf": [{"type": "array", "items": {"$ref": "#/$defs/step"}}, {"type": "null"}]}}}}}, "strict": true}}}}
